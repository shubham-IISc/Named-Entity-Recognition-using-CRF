{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "\n",
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r\"ner.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "with open(file, 'r') as f:\n",
    "    data=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of list of tuples\n",
    "docs=[]\n",
    "doc=[]\n",
    "for sent in data:\n",
    "    if(len(sent)==1):\n",
    "        docs.append(doc)\n",
    "        doc=[]\n",
    "    else:\n",
    "        word1,word2=sent.split()\n",
    "        word_tuple=(word1,word2[-2:])\n",
    "        doc.append(word_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('All', 'O'), ('live', 'O'), ('births', 'O'), ('>', 'O'), ('or', 'O'), ('=', 'O'), ('23', 'O'), ('weeks', 'O'), ('at', 'O'), ('the', 'O'), ('University', 'O'), ('of', 'O'), ('Vermont', 'O'), ('in', 'O'), ('1995', 'O'), ('(', 'O'), ('n', 'O'), ('=', 'O'), ('2395', 'O'), (')', 'O'), ('were', 'O'), ('retrospectively', 'O'), ('analyzed', 'O'), ('for', 'O'), ('delivery', 'O'), ('route', 'O'), (',', 'O'), ('indication', 'O'), ('for', 'O'), ('cesarean', 'O'), (',', 'O'), ('gestational', 'O'), ('age', 'O'), (',', 'O'), ('parity', 'O'), (',', 'O'), ('and', 'O'), ('practice', 'O'), ('group', 'O'), ('(', 'O'), ('to', 'O'), ('reflect', 'O'), ('risk', 'O'), ('status', 'O'), (')', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('All', 'DT', 'O'), ('live', 'JJ', 'O'), ('births', 'NNS', 'O'), ('>', 'VBP', 'O'), ('or', 'CC', 'O'), ('=', 'VBP', 'O'), ('23', 'CD', 'O'), ('weeks', 'NNS', 'O'), ('at', 'IN', 'O'), ('the', 'DT', 'O'), ('University', 'NNP', 'O'), ('of', 'IN', 'O'), ('Vermont', 'NNP', 'O'), ('in', 'IN', 'O'), ('1995', 'CD', 'O'), ('(', '(', 'O'), ('n', 'IN', 'O'), ('=', 'NNP', 'O'), ('2395', 'CD', 'O'), (')', ')', 'O'), ('were', 'VBD', 'O'), ('retrospectively', 'RB', 'O'), ('analyzed', 'VBN', 'O'), ('for', 'IN', 'O'), ('delivery', 'NN', 'O'), ('route', 'NN', 'O'), (',', ',', 'O'), ('indication', 'NN', 'O'), ('for', 'IN', 'O'), ('cesarean', 'NN', 'O'), (',', ',', 'O'), ('gestational', 'JJ', 'O'), ('age', 'NN', 'O'), (',', ',', 'O'), ('parity', 'NN', 'O'), (',', ',', 'O'), ('and', 'CC', 'O'), ('practice', 'NN', 'O'), ('group', 'NN', 'O'), ('(', '(', 'O'), ('to', 'TO', 'O'), ('reflect', 'VB', 'O'), ('risk', 'NN', 'O'), ('status', 'NN', 'O'), (')', ')', 'O')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Appending the POS tags\n",
    "data=[]\n",
    "for doc in docs:\n",
    "    words = [word for word,label in doc ]\n",
    "    pos_tags=nltk.pos_tag(words)\n",
    "    data_sent=[]\n",
    "    for i in range(len(pos_tags)):\n",
    "        data_sent.append((doc[i][0],pos_tags[i][1],doc[i][1]))\n",
    "    data.append(data_sent)\n",
    "    \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features from word net \n",
    "\n",
    "def no_of_contexts(word):\n",
    "    temp=0\n",
    "    for syn in wn.synsets(word):\n",
    "        temp+=1\n",
    "    return temp\n",
    "\n",
    "# if it is alphanumeric\n",
    "def contain_digit(word):\n",
    "    for ch in list(word):\n",
    "        if ch.isdigit()==True:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the report\n",
    "\n",
    "def showreport(y_test,y_pred):\n",
    "    label_dict = {\"O\": 0, \"D\": 1,\"T\":2}\n",
    "   # creating predicted list of entities\n",
    "    model_output=[]\n",
    "    for row in y_pred:\n",
    "        for entity in row:\n",
    "            model_output.append(label_dict[entity])\n",
    "    #creating true list of entities\n",
    "    true_output=[]\n",
    "    for row in y_test:\n",
    "        for entity in row:\n",
    "            true_output.append(label_dict[entity])       \n",
    "    \n",
    "    # Print out the classification report\n",
    "    print(classification_report(true_output, model_output, target_names=[\"O\", \"D\",\"T\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'suffix_3': word[-3:],\n",
    "        #'suffix_2': word[-2:],\n",
    "        'prefix_3':word[:3],\n",
    "        'wordlen':len(word),\n",
    "       'word.isupper': word.isupper(),\n",
    "     'word.isdigit': contain_digit(word),\n",
    "      'postag': postag,\n",
    "        'no_of_contexts':no_of_contexts(word),\n",
    "        'word_stem':sno.stem(word.lower())\n",
    "\n",
    "      }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "\n",
    "         \n",
    "              '-1:wordlen': len(word1),\n",
    "           '-1:word.isupper': word1.isupper(),\n",
    "         '-1:word.isdigit': contain_digit(word1),\n",
    "         '-1:postag': postag1,\n",
    "            '-1:no_of_contexts':no_of_contexts(word1)\n",
    "            \n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "\n",
    "          '+1:word.isupper': word1.isupper(),\n",
    "               '+1:wordlen': len(word1),\n",
    "           '+1:word.isdigit':contain_digit(word1),\n",
    "           '+1:postag': postag1,\n",
    "           '+1:no_of_contexts':no_of_contexts(word1)\n",
    "            \n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words of each document into features reresented in form of dictionary\n",
    "X=[]\n",
    "Y=[]\n",
    "for doc in data:\n",
    "    X.append([word_to_features(doc,i) for i in range(len(doc))])\n",
    "    final_y=[label for (word,pos_tag,label) in doc]\n",
    "    Y.append(final_y)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting in ratio of 70:10:20\n",
    "X_train, X_testanddev, y_train, y_testanddev= train_test_split(X, Y, test_size=0.3,random_state=4)\n",
    "\n",
    "X_test,X_dev, y_test,y_dev = train_test_split(X_testanddev, y_testanddev, test_size=0.33,random_state=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 136.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=None, c2=None,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error...e,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=1,\n",
       "          param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001ECFD3E5DD8>, 'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001ECFD1C30B8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn',\n",
       "          scoring=make_scorer(flat_f1_score, average=macro, labels=['D', 'T', 'O']),\n",
       "          verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper parameter tunning \n",
    "#code referred from crf suite examples\n",
    "\n",
    "\n",
    "labels=[\"D\",\"T\",\"O\"]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', \n",
    "                           max_iterations=1000,\n",
    "                           all_possible_transitions=True,\n",
    "                           verbose=False)\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='macro', labels=labels)\n",
    "\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=10,\n",
    "                        verbose=1,\n",
    "                        n_jobs=1,\n",
    "                        n_iter=20,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for D, T and O label(average) is 0.786411 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.95      0.97      0.96     11355\n",
      "          D       0.76      0.71      0.74       899\n",
      "          T       0.76      0.59      0.66       788\n",
      "\n",
      "avg / total       0.93      0.93      0.93     13042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting the models with obtained hyperparameters c1=.055 and c2=.066\n",
    "\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',c1=0.055,c2=0.066 ,\n",
    "                           max_iterations=1000,\n",
    "                           all_possible_transitions=True,\n",
    "                           verbose=False)\n",
    "crf.fit(X_train,y_train)\n",
    "labels=[\"O\",\"D\",\"T\"]\n",
    "\n",
    "#predicting the entities for test data\n",
    "y_pred=crf.predict(X_test)\n",
    "print(\"F1 score for D, T and O label(average) is %lf \"% (metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='macro', labels=labels)))\n",
    "#printing the classfication report\n",
    "showreport(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
